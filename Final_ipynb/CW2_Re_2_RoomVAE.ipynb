{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "JUCYADP_1Ewv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O6IQkVKu1J_H",
        "outputId": "6694be70-8b01-474e-a90b-2ecfbec18dcf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of input data: (1157, 16, 16, 1)\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess the dataset\n",
        "file_path = 'rooms_dataset.npy'\n",
        "rooms_dataset = np.load(file_path)\n",
        "\n",
        "# Ensure the data has a channels dimension (assumed to be grayscale)\n",
        "rooms_dataset = np.expand_dims(rooms_dataset, axis=-1)  # Adding channel dimension if not present\n",
        "rooms_dataset_normalized = rooms_dataset / np.max(rooms_dataset)\n",
        "rooms_dataset_normalized = rooms_dataset_normalized.astype(np.float32)\n",
        "\n",
        "print(\"Shape of input data:\", rooms_dataset_normalized.shape)  # Should be (num_samples, height, width, channels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "66nAEpQs5E0e"
      },
      "outputs": [],
      "source": [
        "def augment_data(dataset):\n",
        "    augmented_dataset = []\n",
        "    for image in dataset:\n",
        "        image = np.squeeze(image)  # Remove channel dimension for augmentation\n",
        "        # Apply random transformations\n",
        "        image = np.rot90(image, k=np.random.randint(4))\n",
        "        if np.random.rand() > 0.5:\n",
        "            image = np.fliplr(image)\n",
        "        if np.random.rand() > 0.5:\n",
        "            image = np.flipud(image)\n",
        "        augmented_dataset.append(image)\n",
        "    return np.expand_dims(np.array(augmented_dataset), axis=-1)  # Add channel dimension back\n",
        "\n",
        "rooms_dataset_augmented = augment_data(rooms_dataset_normalized)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81R1DAZw97QV",
        "outputId": "dc2c4009-26af-4c40-e9f0-f1e90481196a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 925\n",
            "Validation set size: 232\n"
          ]
        }
      ],
      "source": [
        "# Split dataset into training and validation sets\n",
        "split_ratio = 0.8\n",
        "split_index = int(split_ratio * len(rooms_dataset_normalized))\n",
        "\n",
        "train_dataset = rooms_dataset_normalized[:split_index]\n",
        "val_dataset = rooms_dataset_normalized[split_index:]\n",
        "\n",
        "print(f\"Training set size: {len(train_dataset)}\")\n",
        "print(f\"Validation set size: {len(val_dataset)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "oQ0a663jvOiG"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the VAE model components\n",
        "\n",
        "# # Encoder\n",
        "# def build_encoder(input_shape, latent_dim):\n",
        "#     inputs = layers.Input(shape=input_shape)\n",
        "#     x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "#     x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "#     x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "#     x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "#     x = layers.Flatten()(x)\n",
        "#     x = layers.Dense(128, activation='relu')(x)\n",
        "\n",
        "#     z_mean = layers.Dense(latent_dim)(x)\n",
        "#     z_log_var = layers.Dense(latent_dim)(x)\n",
        "\n",
        "#     return models.Model(inputs, [z_mean, z_log_var], name=\"encoder\")\n",
        "\n",
        "# # Decoder\n",
        "# def build_decoder(latent_dim, output_shape):\n",
        "#     latent_inputs = layers.Input(shape=(latent_dim,))\n",
        "#     x = layers.Dense(4 * 4 * 64, activation='relu')(latent_inputs)  # Adjust size to match intermediate shape\n",
        "#     x = layers.Reshape((4, 4, 64))(x)  # Adjust size to match intermediate shape\n",
        "#     x = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
        "#     x = layers.UpSampling2D((2, 2))(x)  # Shape: (8, 8, 64)\n",
        "#     x = layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n",
        "#     x = layers.UpSampling2D((2, 2))(x)  # Shape: (16, 16, 32)\n",
        "#     x = layers.Conv2DTranspose(16, (3, 3), activation='relu', padding='same')(x)  # Shape: (16, 16, 16)\n",
        "#     outputs = layers.Conv2DTranspose(output_shape[-1], (3, 3), activation='sigmoid', padding='same')(x)  # Shape: (16, 16, 1)\n",
        "\n",
        "#     return models.Model(latent_inputs, outputs, name=\"decoder\")\n",
        "\n",
        "\n",
        "# Decoder\n",
        "def build_decoder(latent_dim, output_shape):\n",
        "    latent_inputs = layers.Input(shape=(latent_dim,))\n",
        "    x = layers.Dense(4 * 4 * 64, activation='relu')(latent_inputs)  # Adjust size to match intermediate shape\n",
        "    x = layers.Reshape((4, 4, 64))(x)  # Adjust size to match intermediate shape\n",
        "    x = layers.Conv2DTranspose(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.UpSampling2D((2, 2))(x)  # Shape: (8, 8, 64)\n",
        "    x = layers.Conv2DTranspose(32, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.UpSampling2D((2, 2))(x)  # Shape: (16, 16, 32)\n",
        "    x = layers.Conv2DTranspose(16, (3, 3), activation='relu', padding='same')(x)  # Shape: (16, 16, 16)\n",
        "    outputs = layers.Conv2DTranspose(output_shape[-1], (3, 3), activation='sigmoid', padding='same')(x)  # Shape: (16, 16, 1)\n",
        "\n",
        "    return models.Model(latent_inputs, outputs, name=\"decoder\")\n",
        "\n",
        "\n",
        "\n",
        "# VAE Model\n",
        "class VAE(tf.keras.Model):\n",
        "    def __init__(self, encoder, decoder, **kwargs):\n",
        "        super(VAE, self).__init__(**kwargs)\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def call(self, inputs):\n",
        "        z_mean, z_log_var = self.encoder(inputs)\n",
        "        z = self.reparameterize(z_mean, z_log_var)\n",
        "        reconstructed = self.decoder(z)\n",
        "        return reconstructed\n",
        "\n",
        "    def reparameterize(self, z_mean, z_log_var):\n",
        "        epsilon = tf.keras.backend.random_normal(shape=tf.shape(z_mean))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "    def compute_loss(self, x, y):\n",
        "        z_mean, z_log_var = self.encoder(x)\n",
        "        reconstructed = self.decoder(self.reparameterize(z_mean, z_log_var))\n",
        "\n",
        "        # Binary cross-entropy loss\n",
        "        reconstruction_loss = tf.reduce_mean(tf.keras.losses.binary_crossentropy(x, reconstructed))\n",
        "\n",
        "        # KL divergence loss with scaling\n",
        "        kl_loss = -0.5 * tf.reduce_mean(tf.reduce_sum(1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var), axis=1))\n",
        "\n",
        "        # Combining losses with weights\n",
        "        total_loss = reconstruction_loss + kl_loss * 0.1\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "# Hyperparameters\n",
        "input_shape = rooms_dataset_normalized.shape[1:]  # Shape of input images\n",
        "latent_dim = 2  # Number of latent dimensions\n",
        "output_shape = input_shape\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "R0SPIGPewtyH"
      },
      "outputs": [],
      "source": [
        "encoder = build_enhanced_encoder(input_shape, latent_dim)  # Use build_enhanced_encoder\n",
        "decoder = build_decoder(latent_dim, output_shape) # Now the build_decoder function is defined and can be called.\n",
        "vae = VAE(encoder, decoder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EzK7SF4Ywz9-",
        "outputId": "f8fd971a-ac78-4bf4-9bf8-f0ee375db67c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100, Loss: 0.3492618203163147, Validation Loss: 0.4537186622619629\n",
            "Epoch 2/100, Loss: 0.3661477565765381, Validation Loss: 0.44387173652648926\n",
            "Epoch 3/100, Loss: 0.35669779777526855, Validation Loss: 0.4426337480545044\n",
            "Epoch 4/100, Loss: 0.357119083404541, Validation Loss: 0.4563891887664795\n",
            "Epoch 5/100, Loss: 0.3205670714378357, Validation Loss: 0.4416847229003906\n",
            "Epoch 6/100, Loss: 0.3161851167678833, Validation Loss: 0.44188788533210754\n",
            "Epoch 7/100, Loss: 0.35339003801345825, Validation Loss: 0.44689133763313293\n",
            "Epoch 8/100, Loss: 0.38451021909713745, Validation Loss: 0.44215986132621765\n",
            "Epoch 9/100, Loss: 0.38458123803138733, Validation Loss: 0.4409007132053375\n",
            "Epoch 10/100, Loss: 0.3043728768825531, Validation Loss: 0.4483341574668884\n",
            "Epoch 11/100, Loss: 0.34008607268333435, Validation Loss: 0.44244736433029175\n",
            "Epoch 12/100, Loss: 0.32090526819229126, Validation Loss: 0.44793739914894104\n",
            "Epoch 13/100, Loss: 0.3317447006702423, Validation Loss: 0.4319906532764435\n",
            "Epoch 14/100, Loss: 0.3526068329811096, Validation Loss: 0.42834118008613586\n",
            "Epoch 15/100, Loss: 0.31839728355407715, Validation Loss: 0.43260347843170166\n",
            "Epoch 16/100, Loss: 0.3005216121673584, Validation Loss: 0.4325653612613678\n",
            "Epoch 17/100, Loss: 0.3020130693912506, Validation Loss: 0.4290871322154999\n",
            "Epoch 18/100, Loss: 0.28340473771095276, Validation Loss: 0.4358537495136261\n",
            "Epoch 19/100, Loss: 0.3396613895893097, Validation Loss: 0.42180371284484863\n",
            "Epoch 20/100, Loss: 0.3063857853412628, Validation Loss: 0.43089306354522705\n",
            "Epoch 21/100, Loss: 0.35541775822639465, Validation Loss: 0.42671772837638855\n",
            "Epoch 22/100, Loss: 0.2927165925502777, Validation Loss: 0.43538784980773926\n",
            "Epoch 23/100, Loss: 0.34635138511657715, Validation Loss: 0.42036300897598267\n",
            "Epoch 24/100, Loss: 0.335750013589859, Validation Loss: 0.43676674365997314\n",
            "Epoch 25/100, Loss: 0.25986820459365845, Validation Loss: 0.4331023693084717\n",
            "Epoch 26/100, Loss: 0.3128570020198822, Validation Loss: 0.4254743754863739\n",
            "Epoch 27/100, Loss: 0.2918056547641754, Validation Loss: 0.4378649592399597\n",
            "Epoch 28/100, Loss: 0.2840779721736908, Validation Loss: 0.4329482316970825\n",
            "Epoch 29/100, Loss: 0.3124890625476837, Validation Loss: 0.42371898889541626\n",
            "Epoch 30/100, Loss: 0.3202940821647644, Validation Loss: 0.42789947986602783\n",
            "Epoch 31/100, Loss: 0.29917851090431213, Validation Loss: 0.42051762342453003\n",
            "Epoch 32/100, Loss: 0.3309033215045929, Validation Loss: 0.4330165684223175\n",
            "Epoch 33/100, Loss: 0.3242766559123993, Validation Loss: 0.42956647276878357\n",
            "Epoch 34/100, Loss: 0.3365289866924286, Validation Loss: 0.4197692573070526\n",
            "Epoch 35/100, Loss: 0.31707432866096497, Validation Loss: 0.42918646335601807\n",
            "Epoch 36/100, Loss: 0.32229718565940857, Validation Loss: 0.4348708689212799\n",
            "Epoch 37/100, Loss: 0.3184104561805725, Validation Loss: 0.42554783821105957\n",
            "Epoch 38/100, Loss: 0.29568588733673096, Validation Loss: 0.43590301275253296\n",
            "Epoch 39/100, Loss: 0.2996237576007843, Validation Loss: 0.4268648326396942\n",
            "Epoch 40/100, Loss: 0.30432069301605225, Validation Loss: 0.4279351234436035\n",
            "Epoch 41/100, Loss: 0.3279942572116852, Validation Loss: 0.4335309863090515\n",
            "Epoch 42/100, Loss: 0.30173930525779724, Validation Loss: 0.4381127953529358\n",
            "Epoch 43/100, Loss: 0.28599345684051514, Validation Loss: 0.43137460947036743\n",
            "Epoch 44/100, Loss: 0.3185877799987793, Validation Loss: 0.4289945363998413\n",
            "Epoch 45/100, Loss: 0.3192625641822815, Validation Loss: 0.43429476022720337\n",
            "Epoch 46/100, Loss: 0.3025420010089874, Validation Loss: 0.4294532239437103\n",
            "Epoch 47/100, Loss: 0.30696800351142883, Validation Loss: 0.4336012303829193\n",
            "Epoch 48/100, Loss: 0.32554715871810913, Validation Loss: 0.428197979927063\n",
            "Epoch 49/100, Loss: 0.2832799255847931, Validation Loss: 0.42649078369140625\n",
            "Epoch 50/100, Loss: 0.32605502009391785, Validation Loss: 0.4294576644897461\n",
            "Epoch 51/100, Loss: 0.31187334656715393, Validation Loss: 0.43032389879226685\n",
            "Epoch 52/100, Loss: 0.32736843824386597, Validation Loss: 0.4302489757537842\n",
            "Epoch 53/100, Loss: 0.3241937756538391, Validation Loss: 0.42206233739852905\n",
            "Epoch 54/100, Loss: 0.3573639988899231, Validation Loss: 0.42781367897987366\n",
            "Epoch 55/100, Loss: 0.2888413369655609, Validation Loss: 0.4312804937362671\n",
            "Epoch 56/100, Loss: 0.2990846633911133, Validation Loss: 0.42941105365753174\n",
            "Epoch 57/100, Loss: 0.3067628741264343, Validation Loss: 0.43127554655075073\n",
            "Epoch 58/100, Loss: 0.2793096899986267, Validation Loss: 0.4320637583732605\n",
            "Epoch 59/100, Loss: 0.2871984541416168, Validation Loss: 0.43552303314208984\n",
            "Epoch 60/100, Loss: 0.32089734077453613, Validation Loss: 0.42654210329055786\n",
            "Epoch 61/100, Loss: 0.3125966191291809, Validation Loss: 0.42976516485214233\n",
            "Epoch 62/100, Loss: 0.3269020617008209, Validation Loss: 0.43873196840286255\n",
            "Epoch 63/100, Loss: 0.30729174613952637, Validation Loss: 0.42245179414749146\n",
            "Epoch 64/100, Loss: 0.2950992286205292, Validation Loss: 0.4507795572280884\n",
            "Epoch 65/100, Loss: 0.30307701230049133, Validation Loss: 0.43040210008621216\n",
            "Epoch 66/100, Loss: 0.31133773922920227, Validation Loss: 0.4267072379589081\n",
            "Epoch 67/100, Loss: 0.31468597054481506, Validation Loss: 0.4371311664581299\n",
            "Epoch 68/100, Loss: 0.3154628276824951, Validation Loss: 0.43484413623809814\n",
            "Epoch 69/100, Loss: 0.29410436749458313, Validation Loss: 0.4233892858028412\n",
            "Epoch 70/100, Loss: 0.29775169491767883, Validation Loss: 0.42915278673171997\n",
            "Epoch 71/100, Loss: 0.2792396545410156, Validation Loss: 0.4425411522388458\n",
            "Epoch 72/100, Loss: 0.30775976181030273, Validation Loss: 0.42832866311073303\n",
            "Epoch 73/100, Loss: 0.31137531995773315, Validation Loss: 0.4318375289440155\n",
            "Epoch 74/100, Loss: 0.3039453327655792, Validation Loss: 0.43900036811828613\n",
            "Epoch 75/100, Loss: 0.30596286058425903, Validation Loss: 0.4358650743961334\n",
            "Epoch 76/100, Loss: 0.35047033429145813, Validation Loss: 0.4276951551437378\n",
            "Epoch 77/100, Loss: 0.3042052090167999, Validation Loss: 0.43114811182022095\n",
            "Epoch 78/100, Loss: 0.3188430070877075, Validation Loss: 0.4312422275543213\n",
            "Epoch 79/100, Loss: 0.29277804493904114, Validation Loss: 0.4354991614818573\n",
            "Epoch 80/100, Loss: 0.29942038655281067, Validation Loss: 0.4295192062854767\n",
            "Epoch 81/100, Loss: 0.30114904046058655, Validation Loss: 0.44024235010147095\n",
            "Epoch 82/100, Loss: 0.3040773272514343, Validation Loss: 0.43180137872695923\n",
            "Epoch 83/100, Loss: 0.3413218855857849, Validation Loss: 0.4350076913833618\n",
            "Epoch 84/100, Loss: 0.3001363277435303, Validation Loss: 0.4289422035217285\n",
            "Epoch 85/100, Loss: 0.3104194700717926, Validation Loss: 0.4435567557811737\n",
            "Epoch 86/100, Loss: 0.3233257830142975, Validation Loss: 0.42487889528274536\n",
            "Epoch 87/100, Loss: 0.2869536578655243, Validation Loss: 0.4440111815929413\n",
            "Epoch 88/100, Loss: 0.30848193168640137, Validation Loss: 0.4258231222629547\n",
            "Epoch 89/100, Loss: 0.31105515360832214, Validation Loss: 0.4302609860897064\n",
            "Epoch 90/100, Loss: 0.2976335287094116, Validation Loss: 0.44720694422721863\n",
            "Epoch 91/100, Loss: 0.31843310594558716, Validation Loss: 0.43465104699134827\n",
            "Epoch 92/100, Loss: 0.31182563304901123, Validation Loss: 0.4295920431613922\n",
            "Epoch 93/100, Loss: 0.36676836013793945, Validation Loss: 0.43074697256088257\n",
            "Epoch 94/100, Loss: 0.31585121154785156, Validation Loss: 0.4269309639930725\n",
            "Epoch 95/100, Loss: 0.34040942788124084, Validation Loss: 0.4350888133049011\n",
            "Epoch 96/100, Loss: 0.33767440915107727, Validation Loss: 0.4281112849712372\n",
            "Epoch 97/100, Loss: 0.3182753622531891, Validation Loss: 0.4309682548046112\n",
            "Epoch 98/100, Loss: 0.30781760811805725, Validation Loss: 0.4285898208618164\n",
            "Epoch 99/100, Loss: 0.32576146721839905, Validation Loss: 0.4356895685195923\n",
            "Epoch 100/100, Loss: 0.3158836364746094, Validation Loss: 0.4392325282096863\n"
          ]
        }
      ],
      "source": [
        "# Compile the model\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "@tf.function\n",
        "def train_step(x):\n",
        "    with tf.GradientTape() as tape:\n",
        "        reconstructed = vae(x, training=True)\n",
        "        loss = vae.compute_loss(x, reconstructed)\n",
        "    grads = tape.gradient(loss, vae.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, vae.trainable_variables))\n",
        "    return loss\n",
        "\n",
        "# def train(epochs, batch_size):\n",
        "#     dataset = tf.data.Dataset.from_tensor_slices(rooms_dataset_normalized).shuffle(1000).batch(batch_size)\n",
        "#     for epoch in range(epochs):\n",
        "#         for batch in dataset:\n",
        "#             loss = train_step(batch)\n",
        "#         print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.numpy()}\")\n",
        "\n",
        "# # Train the model\n",
        "# train(epochs=50, batch_size=64)\n",
        "\n",
        "def train(epochs, batch_size):\n",
        "    train_ds = tf.data.Dataset.from_tensor_slices(train_dataset).shuffle(1000).batch(batch_size)\n",
        "    val_ds = tf.data.Dataset.from_tensor_slices(val_dataset).batch(batch_size)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        # Training\n",
        "        for batch in train_ds:\n",
        "            loss = train_step(batch)\n",
        "\n",
        "        # Validation\n",
        "        val_loss = tf.keras.metrics.Mean()\n",
        "        for batch in val_ds:\n",
        "            val_loss.update_state(vae.compute_loss(batch, batch))\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {loss.numpy()}, Validation Loss: {val_loss.result().numpy()}\")\n",
        "\n",
        "# Train the model\n",
        "train(epochs=100, batch_size=64)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate new rooms\n",
        "def generate_room(latent_dim, decoder):\n",
        "    z = np.random.normal(size=(1, latent_dim))\n",
        "    generated_room = decoder.predict(z)\n",
        "    return generated_room[0]\n",
        "\n",
        "\n",
        "\n",
        "# Generate and display a new room\n",
        "new_room = generate_room(latent_dim, decoder)\n",
        "plt.imshow(new_room.squeeze(), cmap='viridis')\n",
        "plt.title('Generated Room')\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "I-udRMYSJ-hF",
        "outputId": "bd9c04a9-94fe-407f-a83b-5e210b396490"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 26ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def generate_room(latent_dim, decoder):\n",
        "    # Generate random latent vector\n",
        "    z = np.random.normal(size=(1, latent_dim))\n",
        "\n",
        "    # Predict the room using the decoder\n",
        "    generated_room = decoder.predict(z)\n",
        "\n",
        "    # Post-process the image\n",
        "    generated_room = generated_room[0]\n",
        "\n",
        "    # Normalize to [0, 1] if not already normalized\n",
        "    if generated_room.max() > 1:\n",
        "        generated_room = (generated_room - generated_room.min()) / (generated_room.max() - generated_room.min())\n",
        "\n",
        "    # Convert to 0-255 integer values\n",
        "    generated_room = np.clip(generated_room * 255, 0, 255).astype(np.uint8)\n",
        "\n",
        "    return generated_room\n",
        "\n",
        "def display_room(image_array, cmap='viridis'):\n",
        "    plt.figure(figsize=(8, 8))\n",
        "    plt.imshow(image_array.squeeze(), cmap=cmap)\n",
        "    plt.title('Generated Room')\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "\n",
        "# Generate and display a new room\n",
        "new_room = generate_room(latent_dim, decoder)\n",
        "display_room(new_room, cmap='viridis')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 693
        },
        "id": "k7P9snonMcOv",
        "outputId": "0b99916f-3edb-4a1b-b510-2c8bf07ff071"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 68ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}